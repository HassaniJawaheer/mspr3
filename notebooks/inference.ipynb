{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52cf3f3f-e637-4259-90e2-aed5ab25f990",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import logging\n",
    "import holidays\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "class Eco2mixFeaturesMinute:\n",
    "    \"\"\"Adds selected external features to 30-min Eco2mix data.\"\"\"\n",
    "\n",
    "    def __init__(self, df):\n",
    "        self.df = df.copy()\n",
    "        self.df[\"Datetime\"] = pd.to_datetime(self.df[\"Datetime\"])\n",
    "\n",
    "    def add_temperature(self, latitude=48.85, longitude=2.35):\n",
    "        self.df[\"Hour\"] = self.df[\"Datetime\"].dt.floor(\"h\")\n",
    "        start_date = self.df[\"Hour\"].min().strftime(\"%Y-%m-%d\")\n",
    "        end_date = self.df[\"Hour\"].max().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "        params = {\n",
    "            \"latitude\": latitude,\n",
    "            \"longitude\": longitude,\n",
    "            \"start_date\": start_date,\n",
    "            \"end_date\": end_date,\n",
    "            \"hourly\": \"temperature\",\n",
    "            \"timezone\": \"Europe/Paris\"\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            response = requests.get(url, params=params)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            temp_df = pd.DataFrame(data[\"hourly\"])\n",
    "            temp_df[\"Hour\"] = pd.to_datetime(temp_df[\"time\"])\n",
    "            temp_df.drop(columns=[\"time\"], inplace=True)\n",
    "            self.df = self.df.merge(temp_df, on=\"Hour\", how=\"left\")\n",
    "            self.df.drop(columns=[\"Hour\"], inplace=True)\n",
    "\n",
    "            logging.info(\"Temperature features added.\")\n",
    "        except requests.RequestException as e:\n",
    "            logging.error(f\"[API Error - Temperature] {e}\")\n",
    "\n",
    "    def add_sunshine(self, latitude=48.85, longitude=2.35):\n",
    "        self.df[\"Date\"] = self.df[\"Datetime\"].dt.date\n",
    "        start_date = min(self.df[\"Date\"]).strftime(\"%Y-%m-%d\")\n",
    "        end_date = max(self.df[\"Date\"]).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "        params = {\n",
    "            \"latitude\": latitude,\n",
    "            \"longitude\": longitude,\n",
    "            \"start_date\": start_date,\n",
    "            \"end_date\": end_date,\n",
    "            \"daily\": \"sunshine_duration\",\n",
    "            \"timezone\": \"Europe/Paris\"\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            response = requests.get(url, params=params)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            sun_df = pd.DataFrame(data[\"daily\"])\n",
    "            sun_df[\"Date\"] = pd.to_datetime(sun_df[\"time\"]).dt.date\n",
    "            sun_df.drop(columns=[\"time\"], inplace=True)\n",
    "            self.df = self.df.merge(sun_df, on=\"Date\", how=\"left\")\n",
    "            self.df.drop(columns=[\"Date\"], inplace=True)\n",
    "            logging.info(\"Sunshine features added.\")\n",
    "        except requests.RequestException as e:\n",
    "            logging.error(f\"[API Error - Sunshine] {e}\")\n",
    "\n",
    "    def add_weekday(self):\n",
    "        self.df[\"Date\"] = self.df[\"Datetime\"].dt.date\n",
    "        jours_fr = [\"lundi\", \"mardi\", \"mercredi\", \"jeudi\", \"vendredi\", \"samedi\", \"dimanche\"]\n",
    "        self.df[\"weekday\"] = pd.to_datetime(self.df[\"Date\"]).dt.dayofweek.apply(lambda x: jours_fr[x])\n",
    "        self.df.drop(columns=[\"Date\"], inplace=True)\n",
    "        logging.info(\"Weekday column added.\")\n",
    "\n",
    "    def add_month(self):\n",
    "        self.df[\"Date\"] = self.df[\"Datetime\"].dt.date\n",
    "        mois_fr = [\n",
    "            \"janvier\", \"février\", \"mars\", \"avril\", \"mai\", \"juin\",\n",
    "            \"juillet\", \"août\", \"septembre\", \"octobre\", \"novembre\", \"décembre\"\n",
    "        ]\n",
    "        self.df[\"month\"] = pd.to_datetime(self.df[\"Date\"]).dt.month.apply(lambda x: mois_fr[x - 1])\n",
    "        self.df.drop(columns=[\"Date\"], inplace=True)\n",
    "        logging.info(\"Month column added.\")\n",
    "\n",
    "    def add_season(self):\n",
    "        self.df[\"Date\"] = self.df[\"Datetime\"].dt.date\n",
    "\n",
    "        def get_season(month):\n",
    "            return (\n",
    "                \"hiver\" if month in [12, 1, 2] else\n",
    "                \"printemps\" if month in [3, 4, 5] else\n",
    "                \"été\" if month in [6, 7, 8] else\n",
    "                \"automne\"\n",
    "            )\n",
    "        self.df[\"season\"] = pd.to_datetime(self.df[\"Date\"]).dt.month.apply(get_season)\n",
    "        self.df.drop(columns=[\"Date\"], inplace=True)\n",
    "        logging.info(\"Season column added.\")\n",
    "\n",
    "    def add_vacation(self):\n",
    "        self.df[\"Date\"] = self.df[\"Datetime\"].dt.date\n",
    "        years = pd.to_datetime(self.df[\"Date\"]).dt.year.unique()\n",
    "        public_holidays = holidays.FR(years=years)\n",
    "\n",
    "        zone_vacations_by_year = {\n",
    "            \"winter\": (\"02-05\", \"03-07\"),\n",
    "            \"spring\": (\"04-09\", \"05-09\"),\n",
    "            \"summer\": (\"07-06\", \"08-31\"),\n",
    "            \"Toussaint\": (\"10-17\", \"11-02\"),\n",
    "            \"christmas\": (\"12-18\", \"12-31\")\n",
    "        }\n",
    "\n",
    "        vacations = set()\n",
    "        for year in years:\n",
    "            for start, end in zone_vacations_by_year.values():\n",
    "                vacations.update(pd.date_range(start=f\"{year}-{start}\", end=f\"{year}-{end}\").date)\n",
    "\n",
    "        self.df[\"is_vacation\"] = self.df[\"Date\"].apply(lambda d: int(d in public_holidays or d in vacations))\n",
    "        self.df.drop(columns=[\"Date\"], inplace=True)\n",
    "        logging.info(\"Vacation flag added.\")\n",
    "\n",
    "    def run(self, include=None):\n",
    "        include = include or []\n",
    "        if \"temperature\" in include:\n",
    "            self.add_temperature()\n",
    "        if \"sunshine\" in include:\n",
    "            self.add_sunshine()\n",
    "        if \"weekday\" in include:\n",
    "            self.add_weekday()\n",
    "        if \"month\" in include:\n",
    "            self.add_month()\n",
    "        if \"season\" in include:\n",
    "            self.add_season()\n",
    "        if \"vacation\" in include:\n",
    "            self.add_vacation()\n",
    "        return self.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00cb577e-0db0-4817-9cbc-cd87e11f14d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import tempfile\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def read_df(path):\n",
    "    return pd.read_csv(path, sep=\"\\t\", encoding=\"latin1\", index_col=False, low_memory=False)\n",
    "\n",
    "class Eco2mixLivePreparer:\n",
    "    \"\"\"\n",
    "    Prepare recent eco2mix data for inference\n",
    "    \"\"\"\n",
    "    ECO2MIX_LIVE_URL = \"https://eco2mix.rte-france.com/download/eco2mix/eCO2mix_RTE_En-cours-TR.zip\"\n",
    "\n",
    "    def __init__(self, tmp_dir=\"eco2mix_inference\"):\n",
    "        self.tmp_dir = Path(tmp_dir)\n",
    "        self.tmp_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    def load_and_prepare(self, target_date: str) -> pd.DataFrame:\n",
    "        target_dt = pd.to_datetime(target_date)\n",
    "        start_dt = target_dt - timedelta(days=7)\n",
    "\n",
    "        logger.info(f\"Preparing data for inference on target date: {target_date}\")\n",
    "        logger.info(f\"Will extract data from {start_dt.strftime('%Y-%m-%d')} to {target_dt.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "        # 1. Download and extract ZIP\n",
    "        zip_path = self.tmp_dir / \"live.zip\"\n",
    "        response = requests.get(self.ECO2MIX_LIVE_URL)\n",
    "        with open(zip_path, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        logger.info(f\"Downloaded Eco2mix live ZIP to {zip_path}\")\n",
    "\n",
    "        with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "            zip_ref.extractall(self.tmp_dir)\n",
    "        logger.info(f\"Extracted ZIP content to {self.tmp_dir}\")\n",
    "\n",
    "        # 2. Locate the .xls file\n",
    "        xls_files = list(self.tmp_dir.glob(\"*.xls\"))\n",
    "        if not xls_files:\n",
    "            raise FileNotFoundError(\"No .xls file found in the archive.\")\n",
    "        xls_path = xls_files[0]\n",
    "        logger.info(f\"Found XLS file: {xls_path.name}\")\n",
    "\n",
    "        # 3. Read and filter data\n",
    "        df = read_df(xls_path)\n",
    "        df = df.iloc[:-1]  # remove summary row\n",
    "        df = df[[\"Date\", \"Heures\", \"Consommation\"]].dropna()\n",
    "        df[\"Datetime\"] = pd.to_datetime(df[\"Date\"].astype(str) + \" \" + df[\"Heures\"], errors=\"coerce\")\n",
    "        df = df[[\"Datetime\", \"Consommation\"]].dropna()\n",
    "        df = df[df[\"Datetime\"].dt.minute.isin([0, 30])]\n",
    "        df = df[df[\"Datetime\"].between(start_dt, target_dt - timedelta(minutes=30))]\n",
    "        df = df.sort_values(\"Datetime\").reset_index(drop=True)\n",
    "\n",
    "        if len(df) < 288:\n",
    "            raise ValueError(f\"Missing data: only {len(df)} rows found, 288 expected.\")\n",
    "        logger.info(f\"Filtered to {len(df)} rows of 30-minute consumption data.\")\n",
    "\n",
    "        # 4. Enrich with external features\n",
    "        df_features = Eco2mixFeaturesMinute(df)\n",
    "        df = df_features.run(include=[\"temperature\", \"sunshine\", \"weekday\", \"month\", \"season\", \"vacation\"])\n",
    "        logger.info(\"Added external features to data.\")\n",
    "\n",
    "        logger.info(\"Data preparation complete.\")\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef1be737-9b75-4ef2-bed2-a66952de2acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_forecasting import TimeSeriesDataSet\n",
    "import pandas as pd\n",
    "\n",
    "def rebuild_reference_dataset(df: pd.DataFrame, params: dict) -> TimeSeriesDataSet:\n",
    "    \"\"\"\n",
    "    Rebuild the reference TimeSeriesDataSet using the same structure as during training.\n",
    "\n",
    "    Parameters:\n",
    "    - df: full input DataFrame with 'Datetime', 'Consommation', and all features\n",
    "    - params: dict of training parameters (same as used in training phase)\n",
    "\n",
    "    Returns:\n",
    "    - TimeSeriesDataSet object for inference use\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df[\"Datetime\"] = pd.to_datetime(df[\"Datetime\"])\n",
    "    df = df.sort_values(\"Datetime\").reset_index(drop=True)\n",
    "    df[\"time_idx\"] = range(len(df))\n",
    "    df[\"series_id\"] = \"France\"\n",
    "\n",
    "    dataset = TimeSeriesDataSet(\n",
    "        df,\n",
    "        time_idx=\"time_idx\",\n",
    "        target=\"Consommation\",\n",
    "        group_ids=[\"series_id\"],\n",
    "        max_encoder_length=params.get(\"max_encoder_length\", 288),\n",
    "        max_prediction_length=params.get(\"max_prediction_length\", 48),\n",
    "        time_varying_known_reals=params.get(\"known_reals\", []),\n",
    "        time_varying_unknown_reals=params.get(\"unknown_reals\", []),\n",
    "        time_varying_known_categoricals=params.get(\"known_categoricals\", []),\n",
    "        time_varying_unknown_categoricals=params.get(\"unknown_categoricals\", []),\n",
    "        static_reals=params.get(\"static_reals\", []),\n",
    "        static_categoricals=params.get(\"static_categoricals\", []),\n",
    "        target_normalizer=params.get(\"target_normalizer\", None),\n",
    "        add_relative_time_idx=params.get(\"add_relative_time_idx\", True),\n",
    "        add_target_scales=params.get(\"add_target_scales\", True),\n",
    "        add_encoder_length=params.get(\"add_encoder_length\", True)\n",
    "    )\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c269c4c4-ef8f-4517-9a2d-98623fb1a06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pytorch_forecasting import TemporalFusionTransformer\n",
    "from pytorch_forecasting.data import TimeSeriesDataSet\n",
    "import torch\n",
    "\n",
    "class TFTInference:\n",
    "    def __init__(self, model_ckpt_path, reference_dataset):\n",
    "        self.model = TemporalFusionTransformer.load_from_checkpoint(model_ckpt_path, map_location=torch.device(\"cpu\"))\n",
    "        self.reference_dataset = reference_dataset\n",
    "\n",
    "    def predict(self, df_input: pd.DataFrame) -> pd.DataFrame:\n",
    "        df_input = df_input.copy()\n",
    "        df_input[\"Datetime\"] = pd.to_datetime(df_input[\"Datetime\"])\n",
    "        df_input = df_input.sort_values(\"Datetime\").reset_index(drop=True)\n",
    "        df_input[\"time_idx\"] = range(len(df_input))\n",
    "        df_input[\"series_id\"] = \"France\"\n",
    "\n",
    "        # Prepare dataset for prediction\n",
    "        pred_dataset = TimeSeriesDataSet.from_dataset(\n",
    "            self.reference_dataset,\n",
    "            df_input,\n",
    "            predict=True,\n",
    "            stop_randomization=True\n",
    "        )\n",
    "\n",
    "        # Run prediction\n",
    "        loader = pred_dataset.to_dataloader(train=False, batch_size=1)\n",
    "        predictions = self.model.predict(loader)\n",
    "\n",
    "        return {\"prediction\": predictions[0].detach().cpu().numpy()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "050dc55c-90d8-4a62-b4cd-9e115dbfc126",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Preparing data for inference on target date: 2025-05-07\n",
      "INFO:__main__:Will extract data from 2025-04-30 to 2025-05-07\n",
      "INFO:__main__:Downloaded Eco2mix live ZIP to eco2mix_inference/live.zip\n",
      "INFO:__main__:Extracted ZIP content to eco2mix_inference\n",
      "INFO:__main__:Found XLS file: eCO2mix_RTE_En-cours-TR.xls\n",
      "INFO:__main__:Filtered to 336 rows of 30-minute consumption data.\n",
      "INFO:root:Temperature features added.\n",
      "INFO:root:Sunshine features added.\n",
      "INFO:root:Weekday column added.\n",
      "INFO:root:Month column added.\n",
      "INFO:root:Season column added.\n",
      "INFO:root:Vacation flag added.\n",
      "INFO:__main__:Added external features to data.\n",
      "INFO:__main__:Data preparation complete.\n",
      "/home/hassani/EPSI/MSPR/edf_forecasting/.venv/lib/python3.12/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.6.1 when using version 1.5.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/hassani/EPSI/MSPR/edf_forecasting/.venv/lib/python3.12/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "/home/hassani/EPSI/MSPR/edf_forecasting/.venv/lib/python3.12/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Initialize engine\u001b[39;00m\n\u001b[1;32m     24\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/hassani/EPSI/MSPR/edf_forecasting/notebooks/epoch=05-val_loss=967.61.ckpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 25\u001b[0m engine \u001b[38;5;241m=\u001b[39m \u001b[43mTFTInference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreference_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[1;32m     28\u001b[0m result \u001b[38;5;241m=\u001b[39m engine\u001b[38;5;241m.\u001b[39mpredict(df_input)\n",
      "Cell \u001b[0;32mIn[13], line 8\u001b[0m, in \u001b[0;36mTFTInference.__init__\u001b[0;34m(self, model_ckpt_path, reference_dataset)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_ckpt_path, reference_dataset):\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mTemporalFusionTransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_ckpt_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreference_dataset \u001b[38;5;241m=\u001b[39m reference_dataset\n",
      "File \u001b[0;32m~/EPSI/MSPR/edf_forecasting/.venv/lib/python3.12/site-packages/lightning/pytorch/utilities/model_helpers.py:125\u001b[0m, in \u001b[0;36m_restricted_classmethod_impl.__get__.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m instance \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scripting:\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    122\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe classmethod `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` cannot be called on an instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    123\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Please call it on the class type and make sure the return value is used.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    124\u001b[0m     )\n\u001b[0;32m--> 125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/EPSI/MSPR/edf_forecasting/.venv/lib/python3.12/site-packages/lightning/pytorch/core/module.py:1581\u001b[0m, in \u001b[0;36mLightningModule.load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m   1492\u001b[0m \u001b[38;5;129m@_restricted_classmethod\u001b[39m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_from_checkpoint\u001b[39m(\n\u001b[1;32m   1494\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1499\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m   1500\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint it stores the arguments\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;124;03m    passed to ``__init__``  in the checkpoint under ``\"hyper_parameters\"``.\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1579\u001b[0m \n\u001b[1;32m   1580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1581\u001b[0m     loaded \u001b[38;5;241m=\u001b[39m \u001b[43m_load_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1582\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1583\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhparams_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1587\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1588\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1589\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(Self, loaded)\n",
      "File \u001b[0;32m~/EPSI/MSPR/edf_forecasting/.venv/lib/python3.12/site-packages/lightning/pytorch/core/saving.py:99\u001b[0m, in \u001b[0;36m_load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m     device \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m((t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m state_dict\u001b[38;5;241m.\u001b[39mvalues() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, torch\u001b[38;5;241m.\u001b[39mTensor)), torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m0\u001b[39m))\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, pl\u001b[38;5;241m.\u001b[39mLightningModule)\n\u001b[0;32m---> 99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/EPSI/MSPR/edf_forecasting/.venv/lib/python3.12/site-packages/lightning/fabric/utilities/device_dtype_mixin.py:55\u001b[0m, in \u001b[0;36m_DeviceDtypeModuleMixin.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m device, dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39m_parse_to(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)[:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m     54\u001b[0m _update_properties(\u001b[38;5;28mself\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/EPSI/MSPR/edf_forecasting/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1355\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1352\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1353\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1355\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/EPSI/MSPR/edf_forecasting/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:915\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 915\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    918\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    919\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    920\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    925\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    926\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/EPSI/MSPR/edf_forecasting/.venv/lib/python3.12/site-packages/torchmetrics/metric.py:907\u001b[0m, in \u001b[0;36mMetric._apply\u001b[0;34m(self, fn, exclude_state)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    902\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected metric state to be either a Tensor or a list of Tensor, but encountered \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_val\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    903\u001b[0m         )\n\u001b[1;32m    905\u001b[0m \u001b[38;5;66;03m# make sure to update the device attribute\u001b[39;00m\n\u001b[1;32m    906\u001b[0m \u001b[38;5;66;03m# if the dummy tensor moves device by fn function we should also update the attribute\u001b[39;00m\n\u001b[0;32m--> 907\u001b[0m _dummy_tensor \u001b[38;5;241m=\u001b[39m fn(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    908\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_device \u001b[38;5;241m=\u001b[39m _dummy_tensor\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m    909\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype \u001b[38;5;241m=\u001b[39m _dummy_tensor\u001b[38;5;241m.\u001b[39mdtype\n",
      "File \u001b[0;32m~/EPSI/MSPR/edf_forecasting/.venv/lib/python3.12/site-packages/torch/cuda/__init__.py:372\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    371\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 372\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    376\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero."
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "import torch\n",
    "\n",
    "# Prepare input data\n",
    "preparer = Eco2mixLivePreparer()\n",
    "df_input = preparer.load_and_prepare(\"2025-05-07\")\n",
    "\n",
    "params = {\n",
    "    \"max_encoder_length\": 6*48,\n",
    "    \"max_prediction_length\": 48,\n",
    "    \"known_reals\": [\"time_idx\", \"temperature\", \"is_vacation\"],\n",
    "    \"unknown_reals\": [\"Consommation\", \"sunshine_duration\"],\n",
    "    \"known_categoricals\": [\"weekday\", \"month\", \"season\"],\n",
    "}\n",
    "\n",
    "# recreate the reference dataset\n",
    "reference_dataset = rebuild_reference_dataset(df_input, params)\n",
    "\n",
    "# Initialize engine\n",
    "model_path = \"/home/hassani/EPSI/MSPR/edf_forecasting/notebooks/epoch=05-val_loss=967.61.ckpt\"\n",
    "engine = TFTInference(model_path, reference_dataset)\n",
    "\n",
    "# Inference\n",
    "result = engine.predict(df_input)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
